{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "# Python cannot interpret images, so we need to preprocess and clean the data, then our neural network will be able to process the information given by the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) \n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255 \n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model. \n",
    "# Using a CNN model, because it represents the data as grid structures, being the reason why it works well for image classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 21 \n",
    "\n",
    "#Convert class vector (integers) to binary class matrix.\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Flattening the 2D arrays for fully connected layers\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 2.2950 - accuracy: 0.1256 - val_loss: 2.2691 - val_accuracy: 0.1718\n",
      "Epoch 2/21\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 2.2625 - accuracy: 0.1765 - val_loss: 2.2339 - val_accuracy: 0.2154\n",
      "Epoch 3/21\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 2.2264 - accuracy: 0.2200 - val_loss: 2.1955 - val_accuracy: 0.2819\n",
      "Epoch 4/21\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 2.1872 - accuracy: 0.2777 - val_loss: 2.1514 - val_accuracy: 0.3671\n",
      "Epoch 5/21\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 2.1433 - accuracy: 0.3440 - val_loss: 2.1002 - val_accuracy: 0.4480\n",
      "Epoch 6/21\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 2.0918 - accuracy: 0.4142 - val_loss: 2.0414 - val_accuracy: 0.5285\n",
      "Epoch 7/21\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 2.0331 - accuracy: 0.4784 - val_loss: 1.9735 - val_accuracy: 0.5927\n",
      "Epoch 8/21\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 1.9651 - accuracy: 0.5318 - val_loss: 1.8947 - val_accuracy: 0.6425\n",
      "Epoch 9/21\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 1.8863 - accuracy: 0.5790 - val_loss: 1.8041 - val_accuracy: 0.6798\n",
      "Epoch 10/21\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 1.7992 - accuracy: 0.6193 - val_loss: 1.7011 - val_accuracy: 0.7069\n",
      "Epoch 11/21\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 1.6952 - accuracy: 0.6476 - val_loss: 1.5882 - val_accuracy: 0.7362\n",
      "Epoch 12/21\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 1.5879 - accuracy: 0.6729 - val_loss: 1.4690 - val_accuracy: 0.7592\n",
      "Epoch 13/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.4773 - accuracy: 0.6911 - val_loss: 1.3480 - val_accuracy: 0.7772\n",
      "Epoch 14/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.3696 - accuracy: 0.7050 - val_loss: 1.2308 - val_accuracy: 0.7906\n",
      "Epoch 15/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.2577 - accuracy: 0.7212 - val_loss: 1.1224 - val_accuracy: 0.8014\n",
      "Epoch 16/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.1632 - accuracy: 0.7315 - val_loss: 1.0256 - val_accuracy: 0.8110\n",
      "Epoch 17/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.0790 - accuracy: 0.7416 - val_loss: 0.9411 - val_accuracy: 0.8182\n",
      "Epoch 18/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 1.0029 - accuracy: 0.7521 - val_loss: 0.8681 - val_accuracy: 0.8261\n",
      "Epoch 19/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.9351 - accuracy: 0.7629 - val_loss: 0.8051 - val_accuracy: 0.8329\n",
      "Epoch 20/21\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.8756 - accuracy: 0.7717 - val_loss: 0.7516 - val_accuracy: 0.8396\n",
      "Epoch 21/21\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 0.8354 - accuracy: 0.7757 - val_loss: 0.7055 - val_accuracy: 0.8463\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs, \n",
    "                verbose = 1, \n",
    "                validation_data=(x_test, y_test))\n",
    "\n",
    "model.save('histfit.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.7055 - accuracy: 0.8463\n",
      "Test loss :  0.7055470943450928\n",
      "Test accuracy:  0.8463000059127808\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss : ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained weights loaded\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "7\n",
      "8\n",
      "5\n",
      "7\n",
      "0\n",
      "7\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "7\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "6\n",
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "import os\n",
    "import cv2\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "model = load_model('histfit.h5')\n",
    "\n",
    "print('Trained weights loaded')\n",
    "\n",
    "def get_handle():\n",
    "    \"\"\"This function uses the wingui library to get the window handles of all the active windows. \n",
    "    Then, the window with the name as 'tk' is selected and its handle is returned.\"\"\"\n",
    "    toplist = []\n",
    "    windows_list = []\n",
    "    canvas = 0\n",
    "    def enum_win(hwnd, result):\n",
    "        win_text = win32gui.GetWindowText(hwnd)\n",
    "        #print(hwnd, win_text)\n",
    "        windows_list.append((hwnd, win_text))\n",
    "    win32gui.EnumWindows(enum_win, toplist)\n",
    "    for (hwnd, win_text) in windows_list:\n",
    "        if 'tk' == win_text:\n",
    "            canvas = hwnd\n",
    "    return canvas\n",
    "\n",
    "def preprocessing_image():\n",
    "    \"\"\"function to preprocess the image to\"\"\"\n",
    "    image = cv2.imread('test.jpg')\n",
    "    #print(type(image))\n",
    "    grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(grey.copy(), 75, 255, cv2.THRESH_BINARY_INV)\n",
    "    # cv2.imshow('binarized image', thresh)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(type(contours[0]))\n",
    "    # print(len(contours[0]))\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n",
    "    #cv2.imshow('Contours', image) \n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)        \n",
    "        # Creating a rectangle around the digit in the original image (for displaying the digits fetched via contours)\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), color=(0, 255, 0), thickness=2)\n",
    "        # Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "        digit = thresh[y:y+h, x:x+w]        \n",
    "        # Resizing that digit to (18, 18)\n",
    "        resized_digit = cv2.resize(digit, (18,18))        \n",
    "        # Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "        padded_digit = np.pad(resized_digit, ((5,5),(5,5)), \"constant\", constant_values=0)        \n",
    "        # Adding the preprocessed digit to the list of preprocessed digits\n",
    "        preprocessed_digit = (padded_digit)\n",
    "    return preprocessed_digit\n",
    "\n",
    "def predict_digit(img):\n",
    "    \"\"\"function to predict the digit. \n",
    "    Argument of function is PIL Image\"\"\"\n",
    "    img.save('test.jpg')\n",
    "    preprocessed_image = preprocessing_image()\n",
    "    # print(type(preprocessed_image))\n",
    "    # print(preprocessed_image.shape)\n",
    "    img = preprocessed_image.reshape(1, 28, 28, 1)\n",
    "    img = img/255.0\n",
    "    #predicting the digit\n",
    "    result = model.predict([img])[0]\n",
    "    os.remove('test.jpg')\n",
    "    return np.argmax(result), max(result)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        hwnd = get_handle()\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        x1, y1, x2, y2 = rect\n",
    "        # print(x1,x2, y1,y2)\n",
    "        im = ImageGrab.grab((x1+40, y1+40, x2+100, y2+100))\n",
    "        digit, acc = predict_digit(im)\n",
    "        print(digit)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
